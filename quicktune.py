import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
import pandas as pd
import os
import csv
if torch.cuda.is_available():
    print("CUDA disponible ‚úÖ")
    # V√©rification d'une op√©ration d'attention optimis√©e
    try:
        torch.nn.functional.scaled_dot_product_attention(
            torch.randn(1, 12, 128, 64).cuda(),
            torch.randn(1, 12, 128, 64).cuda(),
            torch.randn(1, 12, 128, 64).cuda()
        )
        print("Flash Attention activ√© ‚úÖ")
    except Exception as e:
        print("Flash Attention indisponible :", e)
else:
    print("CUDA non disponible ‚ùå")
# Param√®tres globaux
MODEL_PATH = "./bert_multilingual_classification"
DATASET_PATH = "./dataset.csv"
LEARNING_RATE = 1e-5
MAX_LENGTH = 128

# Charger le mod√®le et le tokenizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
model = BertForSequenceClassification.from_pretrained(MODEL_PATH)
model.to(device)
optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)

# Charger ou cr√©er le dataset
if not os.path.exists(DATASET_PATH):
    print("Le fichier dataset.csv est manquant. Cr√©ation d'un nouveau fichier...")
    with open(DATASET_PATH, "w") as f:
        f.write('"text","label"\n')

# Fonction pour pr√©dire une phrase
def predict_sentence(text):
    model.eval()
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=MAX_LENGTH)
    inputs = {key: val.to(device) for key, val in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits
    predicted_label = torch.argmax(logits, dim=-1).item()
    confidence_score = torch.nn.functional.softmax(logits, dim=-1)[0][predicted_label].item()
    label_map = {0: "‚ö™ Neutre", 1: "üü¶ Droite", 2: "üü• Gauche"}
    return label_map[predicted_label], confidence_score, predicted_label

# Fonction pour fine-tuner le mod√®le avec une nouvelle phrase
def fine_tune_model(text, label):
    model.train()
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=MAX_LENGTH)
    inputs = {key: val.to(device) for key, val in inputs.items()}
    labels = torch.tensor([label]).to(device)

    outputs = model(**inputs, labels=labels)
    loss = outputs.loss
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    print(f"‚úÖ Fine-tuning effectu√© avec succ√®s. Perte : {loss.item():.4f}")

# Ajouter la correction au dataset
def add_to_dataset(text, label):
    # Lire le contenu existant du dataset
    existing_data = set()
    with open(DATASET_PATH, mode='r', encoding='utf-8') as file:
        reader = csv.reader(file, quoting=csv.QUOTE_ALL)
        for row in reader:
            if len(row) >= 2:  # V√©rifie qu'une ligne contient bien un texte et un label
                existing_data.add((row[0], row[1]))

    # V√©rifier si la phrase est d√©j√† pr√©sente
    if (text, str(label)) in existing_data:
        print(f"‚ö†Ô∏è La phrase existe d√©j√† dans le dataset : \"{text}\",\"{label}\"")
        return

    # Ajouter la nouvelle phrase si elle n'existe pas
    with open(DATASET_PATH, mode='a', newline='', encoding='utf-8') as file:
        writer = csv.writer(file, quoting=csv.QUOTE_ALL)
        writer.writerow([text, str(label)])

    print(f"‚úÖ Phrase ajout√©e au dataset : \"{text}\",\"{label}\"")

# Menu interactif
# Menu interactif
def interactive_menu():
    print("üéâ Bienvenue dans le menu interactif de test et correction BERT üéâ\n")
    while True:
        # Entr√©e de la phrase
        text = input("Entrez une phrase (ou 'exit' pour quitter) : ").strip()
        if text.lower() == 'exit':
            print("üëã Au revoir !")
            break

        # Pr√©diction
        predicted_label, confidence, label_id = predict_sentence(text)
        print(f"\nüîç Pr√©diction : {predicted_label} (Score de confiance : {confidence:.2f})")

        # V√©rification de la pr√©diction
        is_correct = input("La pr√©diction est-elle correcte ? (y/n) : ").strip().lower()
        if is_correct == "y":
            print("üëç Super, pr√©diction correcte !")
            # Ajouter au dataset si elle n'est pas d√©j√† pr√©sente
            add_to_dataset(text, label_id)
        elif is_correct == "n":
            # Entr√©e du bon label
            print("‚ùå Pr√©diction incorrecte. Veuillez entrer le bon label :")
            print("0 = Neutre, 1 = Droite, 2 = Gauche")
            correct_label = int(input("Entrez le label correct : ").strip())
            if correct_label not in [0, 1, 2]:
                print("‚ö†Ô∏è Label invalide. R√©essayez.\n")
                continue

            # Fine-tuning l√©ger et ajout au dataset
            fine_tune_model(text, correct_label)
            add_to_dataset(text, correct_label)
        else:
            print("‚ö†Ô∏è Entr√©e invalide. R√©pondez par 'y' ou 'n'.\n")


# Lancer le menu interactif
if __name__ == "__main__":
    interactive_menu()
